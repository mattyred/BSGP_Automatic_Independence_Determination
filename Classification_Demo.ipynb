{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSGP model Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import  TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_pth(name, csv_path, pth_path, header=None, clf=False):\n",
    "    def dataframe_to_arrays(df):\n",
    "        df_ = df.copy(deep=True)\n",
    "        X = np.atleast_2d(df_[input_cols].to_numpy())\n",
    "        Y = np.atleast_2d(df_[output_cols].to_numpy().reshape(-1,1))\n",
    "        return X, Y\n",
    "    dataframe_raw = pd.read_csv(csv_path, delimiter=',', header=header)\n",
    "    dataframe_raw.head()\n",
    "    input_cols = list(dataframe_raw.columns)[:-1]\n",
    "    output_cols = list(dataframe_raw.columns)[-1]\n",
    "    X, Y = dataframe_to_arrays(dataframe_raw)\n",
    "    Y[Y==-1] = 0 if clf else None\n",
    "    X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    inputs = torch.tensor(X, dtype=torch.float64)\n",
    "    targets = torch.tensor(Y, dtype=torch.float64)\n",
    "    torch.save([inputs, targets], pth_path + name + '.pth')\n",
    "    return input_cols, output_cols\n",
    "input_cols, output_cols = csv_to_pth(\"credit\", \"data/credit.csv\", \"data/\", clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, static, fold):\n",
    "    dataset_path = ('./data/' + dataset + '.pth')\n",
    "    dataset = TensorDataset(*torch.load(dataset_path))\n",
    "    X, Y = dataset.tensors\n",
    "    X, Y = X.numpy(), Y.numpy()\n",
    "\n",
    "    if static == False:\n",
    "        Y_mean, Y_std = Y.mean(0), Y.std(0) + 1e-9\n",
    "        #Y = (Y - Y_mean) / Y_std\n",
    "        return X, Y, Y_mean, Y_std\n",
    "    else:\n",
    "        #X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=fold)\n",
    "        X_train_indices_boolean = np.random.choice([1, 0], size=X.shape[0], p=[0.8, 0.2])\n",
    "        X_train_indices = np.where(X_train_indices_boolean == 1)[0]\n",
    "        X_test_indices = np.where(X_train_indices_boolean == 0)[0]\n",
    "        X_train = X[X_train_indices]\n",
    "        Y_train = Y[X_train_indices]\n",
    "        X_test = X[X_test_indices]\n",
    "        Y_test = Y[X_test_indices]\n",
    "        Y_train_mean, Y_train_std = Y_train.mean(0), Y_train.std(0) + 1e-9\n",
    "        #Y_train = (Y_train - Y_train_mean) / Y_train_std\n",
    "        #Y_test = (Y_test - Y_train_mean) / Y_train_std\n",
    "        return X_train, Y_train, X_test, Y_test, Y_train_mean, Y_train_std, X_train_indices, X_test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, Y_train_mean, Y_train_std, _, _ = create_dataset('credit', True, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPFlow Classification with RBF-AID kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import gpflow\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lower_triangular_from_diag(d):\n",
    "    \"\"\"\n",
    "    diag: diagonal of lengthscales parameter [D,]\n",
    "    ---\n",
    "    Σ=inv(Λ) -> diagonal matrix with lengthscales on the diagonal (RBF)\n",
    "    The diagonal of Λ is obtained as 1/(l^2), l is a lengthscale\n",
    "    returns: L, Λ=LLᵀ\n",
    "    \"\"\"\n",
    "    # Define the lengthscales according to the standard RBF kernel\n",
    "    lengthscales = np.full((d,), d**0.5, dtype=np.float64) # lengthscales = tf.constant([d**0.5]*d, dtype=tf.float64)\n",
    "    # Obtain the matrix L such that LLᵀ=Λ and Λ=inv(diag(lengthscales))\n",
    "    Lambda = np.diag(1/(lengthscales**2)) # Lambda = tf.linalg.diag(1/(lengthscales**2))\n",
    "    L = scipy.linalg.cholesky(Lambda, lower=True) # L = Cholesky(inv(diag(lengthscales)))\n",
    "    return tfp.math.fill_triangular_inverse(L, upper=False) \n",
    "class Kernel(object):\n",
    "    \"\"\"\n",
    "    The basic kernel class. Handles input_dim and active dims, and provides a\n",
    "    generic '_slice' function to implement them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, active_dims=None, name=None):\n",
    "        \"\"\"\n",
    "        input dim is an integer\n",
    "        active dims is either an iterable of integers or None.\n",
    "        Input dim is the number of input dimensions to the kernel. If the\n",
    "        kernel is computed on a matrix X which has more columns than input_dim,\n",
    "        then by default, only the first input_dim columns are used. If\n",
    "        different columns are required, then they may be specified by\n",
    "        active_dims.\n",
    "        If active dims is None, it effectively defaults to range(input_dim),\n",
    "        but we store it as a slice for efficiency.\n",
    "        \"\"\"\n",
    "        self.input_dim = int(input_dim)\n",
    "        if active_dims is None:\n",
    "            self.active_dims = slice(input_dim)\n",
    "        elif isinstance(active_dims, slice):\n",
    "            self.active_dims = active_dims\n",
    "            if active_dims.start is not None and active_dims.stop is not None and active_dims.step is not None:\n",
    "                assert len(range(active_dims.start, active_dims.stop, active_dims.step)) == input_dim\n",
    "        else:\n",
    "            self.active_dims = np.array(active_dims, dtype=np.int32)\n",
    "            assert len(active_dims) == input_dim\n",
    "\n",
    "    def _validate_ard_shape(self, name, value, ARD=None):\n",
    "        \"\"\"\n",
    "        Validates the shape of a potentially ARD hyperparameter\n",
    "        :param name: The name of the parameter (used for error messages)\n",
    "        :param value: A scalar or an array.\n",
    "        :param ARD: None, False, or True. If None, infers ARD from shape of value.\n",
    "        :return: Tuple (value, ARD), where _value_ is a scalar if input_dim==1 or not ARD, array otherwise.\n",
    "            The _ARD_ is False if input_dim==1 or not ARD, True otherwise.\n",
    "        \"\"\"\n",
    "        if ARD is None:\n",
    "            ARD = np.asarray(value).squeeze().shape != ()\n",
    "\n",
    "        if ARD:\n",
    "            # accept float or array:\n",
    "            value = value * np.ones(self.input_dim, dtype=float)\n",
    "\n",
    "        if self.input_dim == 1 or not ARD:\n",
    "            correct_shape = ()\n",
    "        else:\n",
    "            correct_shape = (self.input_dim,)\n",
    "\n",
    "        if np.asarray(value).squeeze().shape != correct_shape:\n",
    "            raise ValueError(\"shape of {} does not match input_dim\".format(name))\n",
    "\n",
    "        return value, ARD\n",
    "\n",
    "    def compute_K(self, X, Z):\n",
    "        return self.K(X, Z)\n",
    "\n",
    "    def compute_K_symm(self, X):\n",
    "        return self.K(X)\n",
    "\n",
    "    def compute_Kdiag(self, X):\n",
    "        return self.Kdiag(X)\n",
    "\n",
    "    def on_separate_dims(self, other_kernel):\n",
    "        \"\"\"\n",
    "        Checks if the dimensions, over which the kernels are specified, overlap.\n",
    "        Returns True if they are defined on different/separate dimensions and False otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(self.active_dims, slice) or isinstance(other_kernel.active_dims, slice):\n",
    "            # Be very conservative for kernels defined over slices of dimensions\n",
    "            return False\n",
    "\n",
    "        if np.any(self.active_dims.reshape(-1, 1) == other_kernel.active_dims.reshape(1, -1)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _slice(self, X, X2):\n",
    "        \"\"\"\n",
    "        Slice the correct dimensions for use in the kernel, as indicated by\n",
    "        `self.active_dims`.\n",
    "        :param X: Input 1 (NxD).\n",
    "        :param X2: Input 2 (MxD), may be None.\n",
    "        :return: Sliced X, X2, (Nxself.input_dim).\n",
    "        \"\"\"\n",
    "        if isinstance(self.active_dims, slice):\n",
    "            X = X[..., self.active_dims]\n",
    "            if X2 is not None:\n",
    "                X2 = X2[..., self.active_dims]\n",
    "        else:\n",
    "            X = tf.gather(X, self.active_dims, axis=-1)\n",
    "            if X2 is not None:\n",
    "                X2 = tf.gather(X2, self.active_dims, axis=-1)\n",
    "\n",
    "        input_dim_shape = tf.shape(X)[-1]\n",
    "        input_dim = tf.convert_to_tensor(self.input_dim, dtype=tf.int32)\n",
    "        with tf.control_dependencies([tf.assert_equal(input_dim_shape, input_dim)]):\n",
    "            X = tf.identity(X)\n",
    "\n",
    "        return X, X2\n",
    "\n",
    "    def _slice_cov(self, cov):\n",
    "        \"\"\"\n",
    "        Slice the correct dimensions for use in the kernel, as indicated by\n",
    "        `self.active_dims` for covariance matrices. This requires slicing the\n",
    "        rows *and* columns. This will also turn flattened diagonal\n",
    "        matrices into a tensor of full diagonal matrices.\n",
    "        :param cov: Tensor of covariance matrices (NxDxD or NxD).\n",
    "        :return: N x self.input_dim x self.input_dim.\n",
    "        \"\"\"\n",
    "        cov = tf.cond(tf.equal(tf.rank(cov), 2), lambda: tf.matrix_diag(cov), lambda: cov)\n",
    "\n",
    "        if isinstance(self.active_dims, slice):\n",
    "            cov = cov[..., self.active_dims, self.active_dims]\n",
    "        else:\n",
    "            cov_shape = tf.shape(cov)\n",
    "            covr = tf.reshape(cov, [-1, cov_shape[-1], cov_shape[-1]])\n",
    "            gather1 = tf.gather(tf.transpose(covr, [2, 1, 0]), self.active_dims)\n",
    "            gather2 = tf.gather(tf.transpose(gather1, [1, 0, 2]), self.active_dims)\n",
    "            cov = tf.reshape(tf.transpose(gather2, [2, 0, 1]),\n",
    "                             tf.concat([cov_shape[:-2], [len(self.active_dims), len(self.active_dims)]], 0))\n",
    "        return cov\n",
    "\n",
    "class FullPrecisionRBF(gpflow.kernels.Kernel):  \n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        randomized = kwargs[\"randomized\"]\n",
    "        self.d = kwargs[\"d\"]\n",
    "        self.prior_precision_info = kwargs[\"prior_precision_info\"]\n",
    "        self._v = kwargs[\"variance\"]\n",
    "        if not randomized:\n",
    "            L = get_lower_triangular_from_diag(self.d)\n",
    "        super().__init__()\n",
    "        self.L = tf.Variable(L, name='L', dtype=tf.float64)\n",
    "        self.logvariance = tf.Variable(np.log(self._v), dtype=tf.float64, name='log_variance', trainable=False)\n",
    "        self.variance = tf.exp(self.logvariance)\n",
    "\n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"\n",
    "            X: matrix NxD\n",
    "            X2: matrix NxD\n",
    "            ---\n",
    "            Returns Kernel matrix as a 2D tensor\n",
    "        \"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "        N1 = tf.squeeze(tf.shape(X)[:-1])\n",
    "        N2 = tf.squeeze(tf.shape(X2)[:-1])\n",
    "        Lambda = self.precision() # recover UᵀU\n",
    "\n",
    "        # compute z, z2\n",
    "        z = self._z(X, Lambda) # N1x1 array\n",
    "        z2 = self._z(X2, Lambda) # N2x1 array\n",
    "        # compute X(X2Λ)ᵀ\n",
    "        X2Lambda = tf.linalg.matmul(X2, Lambda)\n",
    "        XX2LambdaT = tf.linalg.matmul(X, tf.transpose(X2Lambda)) # N1xN2 matrix\n",
    "        # compute z1ᵀ \n",
    "        ones_N2 = tf.ones(shape=(N2,1), dtype=tf.float64) # N2x1 array\n",
    "        zcol = tf.linalg.matmul(z, tf.transpose(ones_N2)) # N1xN2 matrix\n",
    "        # compute 1z2ᵀ \n",
    "        ones_N1 = tf.ones(shape=(N1,1), dtype=tf.float64) # N1x1 array\n",
    "        zrow = tf.linalg.matmul(ones_N1, tf.transpose(z2)) # N1xN2 matrix\n",
    "\n",
    "        exp_arg = zcol - 2*XX2LambdaT + zrow\n",
    "        Kxx = tf.math.exp(-0.5 * exp_arg)\n",
    "        return self.variance * Kxx\n",
    "    \n",
    "    def K_diag(self, X):\n",
    "        return tf.fill(tf.shape(X)[:-1], tf.squeeze(self.variance))\n",
    "    \n",
    "    def _z(self, X, Lambda):\n",
    "        XLambda = tf.linalg.matmul(X, Lambda)\n",
    "        XLambdaX = tf.math.multiply(XLambda, X)\n",
    "        return tf.math.reduce_sum(XLambdaX, axis=1, keepdims=True)\n",
    "    \n",
    "    def precision(self):\n",
    "        L = tfp.math.fill_triangular(self.L, upper=False) # recover L matrix from L array\n",
    "        Lambda = tf.linalg.matmul(L, tf.transpose(L))\n",
    "        return Lambda\n",
    "    \n",
    "    def precision_off_diagonals(self):\n",
    "        diag_L = tf.linalg.tensor_diag_part(self.precision())\n",
    "        return self.precision() - tf.linalg.diag(diag_L)\n",
    "    \n",
    "    def precision_off_diagonals_prot(self):\n",
    "        return tf.boolean_mask(self.precision(), ~tf.eye(self.d, self.d, dtype=tf.bool))\n",
    "    \n",
    "    def __str__(self):\n",
    "        Lambda = self.precision()\n",
    "        return 'Variance: {}\\nLambda: {}'.format(self.variance, Lambda)\n",
    "    def __str__(self):\n",
    "        if self.prior_precision_info['type'] is not None:\n",
    "            prior_precision_info_str = ' Prior precision type = %s'%(self.prior_precision_info['type'])\n",
    "            if self.prior_precision_info['type'] == 'laplace' or self.prior_precision_info['type'] == 'laplace-diagnormal':\n",
    "                prior_precision_info_str +=  ' (b = %.2f)'%self.prior_precision_info['hparams']\n",
    "        else:\n",
    "            prior_precision_info_str = ' Prior precision type = None' \n",
    "        str = [\n",
    "            '======= Kernel: FullPrecisionRBF (param: LLᵀ)',\n",
    "            # ' Input dim = %d' % self.input_dim,\n",
    "            ' Variance = %.3f' % self._v,\n",
    "            prior_precision_info_str\n",
    "        ]\n",
    "        return '\\n'.join(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                  </th><th>class           </th><th>transform     </th><th>prior  </th><th>trainable  </th><th>shape        </th><th>dtype  </th><th>value                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>VGP.kernel.L          </td><td>ResourceVariable</td><td>              </td><td>       </td><td>True       </td><td>(300,)       </td><td>float64</td><td>[-0.0000e+00, -3.0000e-05, 2.0000e-05...</td></tr>\n",
       "<tr><td>VGP.kernel.logvariance</td><td>ResourceVariable</td><td>              </td><td>       </td><td>False      </td><td>()           </td><td>float64</td><td>-2.30259                                </td></tr>\n",
       "<tr><td>VGP.num_data          </td><td>Parameter       </td><td>Identity      </td><td>       </td><td>False      </td><td>()           </td><td>int32  </td><td>791                                     </td></tr>\n",
       "<tr><td>VGP.q_mu              </td><td>Parameter       </td><td>Identity      </td><td>       </td><td>True       </td><td>(791, 1)     </td><td>float64</td><td>[[-4.43998e+00...                       </td></tr>\n",
       "<tr><td>VGP.q_sqrt            </td><td>Parameter       </td><td>FillTriangular</td><td>       </td><td>True       </td><td>(1, 791, 791)</td><td>float64</td><td>[[[5.7030e-01, 0.0000e+00, 0.0000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior_precision_info = {'type': None, 'hparams': 0.01}\n",
    "kernel = FullPrecisionRBF(variance=0.1, randomized=False, d=24, prior_precision_info=prior_precision_info) \n",
    "model = gpflow.models.VGP(\n",
    "    (X_train, Y_train),\n",
    "    kernel=kernel,\n",
    "    likelihood=gpflow.likelihoods.Bernoulli(),\n",
    ")\n",
    "opt = gpflow.optimizers.Scipy()\n",
    "opt.minimize(model.training_loss, model.trainable_variables)\n",
    "gpflow.utilities.print_summary(model, \"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(209, 1), dtype=float64, numpy=\n",
       "array([[ 7.64729352],\n",
       "       [75.56013647],\n",
       "       [77.16712623],\n",
       "       [60.33154186],\n",
       "       [ 3.60744864],\n",
       "       [17.97414663],\n",
       "       [15.2417648 ],\n",
       "       [28.94975908],\n",
       "       [14.91030896],\n",
       "       [28.89962998],\n",
       "       [30.65142862],\n",
       "       [ 9.1191783 ],\n",
       "       [ 8.44511274],\n",
       "       [ 4.93532558],\n",
       "       [53.3570071 ],\n",
       "       [54.49802244],\n",
       "       [ 5.3321138 ],\n",
       "       [ 8.61706585],\n",
       "       [11.74476089],\n",
       "       [38.75809569],\n",
       "       [62.39302692],\n",
       "       [15.8642893 ],\n",
       "       [57.14098766],\n",
       "       [ 9.02918977],\n",
       "       [44.24080637],\n",
       "       [21.90388025],\n",
       "       [37.09122673],\n",
       "       [17.01758205],\n",
       "       [54.91047181],\n",
       "       [63.78101707],\n",
       "       [17.57982039],\n",
       "       [64.54544546],\n",
       "       [43.03435496],\n",
       "       [11.52393857],\n",
       "       [15.12822299],\n",
       "       [24.27961165],\n",
       "       [63.84336629],\n",
       "       [21.86451686],\n",
       "       [71.20866495],\n",
       "       [11.15715203],\n",
       "       [ 8.03279558],\n",
       "       [ 5.35864398],\n",
       "       [ 2.92481141],\n",
       "       [36.17614295],\n",
       "       [30.52619914],\n",
       "       [ 8.18498649],\n",
       "       [54.9148279 ],\n",
       "       [51.39871693],\n",
       "       [11.26850207],\n",
       "       [73.53010002],\n",
       "       [ 5.97983388],\n",
       "       [44.85054262],\n",
       "       [ 7.9806198 ],\n",
       "       [35.95215188],\n",
       "       [42.98735322],\n",
       "       [44.94686337],\n",
       "       [62.63781637],\n",
       "       [20.24950833],\n",
       "       [ 6.67896637],\n",
       "       [60.27526645],\n",
       "       [23.83991663],\n",
       "       [57.30749488],\n",
       "       [24.95023531],\n",
       "       [71.30241516],\n",
       "       [48.39907937],\n",
       "       [21.63558717],\n",
       "       [16.06911613],\n",
       "       [47.38901779],\n",
       "       [32.56019248],\n",
       "       [46.69620386],\n",
       "       [ 4.67031451],\n",
       "       [11.31021253],\n",
       "       [ 5.08708384],\n",
       "       [66.14094371],\n",
       "       [ 6.42497309],\n",
       "       [ 5.04692067],\n",
       "       [18.07486072],\n",
       "       [35.41703167],\n",
       "       [49.11733074],\n",
       "       [33.14924191],\n",
       "       [18.09331378],\n",
       "       [35.58762852],\n",
       "       [42.43967029],\n",
       "       [ 7.33520804],\n",
       "       [55.63443981],\n",
       "       [18.04077402],\n",
       "       [12.1242907 ],\n",
       "       [31.40233383],\n",
       "       [ 3.17677342],\n",
       "       [ 7.79855017],\n",
       "       [47.49063112],\n",
       "       [26.31345482],\n",
       "       [11.80330843],\n",
       "       [11.3694148 ],\n",
       "       [ 4.63908427],\n",
       "       [33.01520599],\n",
       "       [ 2.78536967],\n",
       "       [10.27998271],\n",
       "       [26.92524511],\n",
       "       [59.23250019],\n",
       "       [ 5.68486884],\n",
       "       [41.29823499],\n",
       "       [21.92445702],\n",
       "       [66.54384307],\n",
       "       [18.21860183],\n",
       "       [ 8.32051905],\n",
       "       [ 8.97222452],\n",
       "       [66.61961646],\n",
       "       [ 4.91468281],\n",
       "       [40.5152638 ],\n",
       "       [25.85344613],\n",
       "       [20.7828881 ],\n",
       "       [58.45739161],\n",
       "       [39.99698193],\n",
       "       [ 3.43479914],\n",
       "       [ 7.38515348],\n",
       "       [42.5840497 ],\n",
       "       [37.07225906],\n",
       "       [ 4.70741566],\n",
       "       [75.27190459],\n",
       "       [13.19351947],\n",
       "       [56.521079  ],\n",
       "       [50.03563195],\n",
       "       [28.44304895],\n",
       "       [22.20851513],\n",
       "       [47.16233172],\n",
       "       [50.150201  ],\n",
       "       [65.76983986],\n",
       "       [16.72571957],\n",
       "       [14.66576929],\n",
       "       [ 9.68148704],\n",
       "       [25.14184989],\n",
       "       [42.01002843],\n",
       "       [55.06116046],\n",
       "       [29.94214774],\n",
       "       [30.5339224 ],\n",
       "       [54.48775263],\n",
       "       [50.65828312],\n",
       "       [ 3.34089935],\n",
       "       [18.6312275 ],\n",
       "       [14.69649821],\n",
       "       [22.33536345],\n",
       "       [36.32185215],\n",
       "       [11.41921283],\n",
       "       [17.60759442],\n",
       "       [19.89239054],\n",
       "       [17.98122351],\n",
       "       [37.27496009],\n",
       "       [48.81928629],\n",
       "       [ 7.98298753],\n",
       "       [11.8682263 ],\n",
       "       [ 3.12999245],\n",
       "       [56.54861232],\n",
       "       [30.82598207],\n",
       "       [ 4.72943148],\n",
       "       [47.53906768],\n",
       "       [29.18407783],\n",
       "       [24.15163443],\n",
       "       [10.92213783],\n",
       "       [ 9.96363405],\n",
       "       [13.96617284],\n",
       "       [ 5.27557849],\n",
       "       [73.13830449],\n",
       "       [45.95552937],\n",
       "       [14.63110566],\n",
       "       [ 4.64195846],\n",
       "       [22.73346935],\n",
       "       [42.08921081],\n",
       "       [66.2724414 ],\n",
       "       [13.13681829],\n",
       "       [74.34658874],\n",
       "       [11.96171154],\n",
       "       [22.66480081],\n",
       "       [37.76583107],\n",
       "       [16.34893632],\n",
       "       [12.1688878 ],\n",
       "       [31.23013686],\n",
       "       [73.05417638],\n",
       "       [28.51706059],\n",
       "       [48.96693475],\n",
       "       [52.790461  ],\n",
       "       [25.00663064],\n",
       "       [13.96439835],\n",
       "       [59.26468811],\n",
       "       [40.21715942],\n",
       "       [11.13041019],\n",
       "       [11.1618326 ],\n",
       "       [16.22370553],\n",
       "       [30.92683749],\n",
       "       [ 5.06112963],\n",
       "       [36.63462446],\n",
       "       [14.52057076],\n",
       "       [57.70731467],\n",
       "       [ 4.77123011],\n",
       "       [14.25916989],\n",
       "       [63.56939589],\n",
       "       [39.10465859],\n",
       "       [29.51091671],\n",
       "       [ 6.25786392],\n",
       "       [57.22354705],\n",
       "       [25.39077989],\n",
       "       [20.72859297],\n",
       "       [ 6.2251289 ],\n",
       "       [ 3.41385672],\n",
       "       [45.84208193],\n",
       "       [13.03642184],\n",
       "       [32.13689424],\n",
       "       [ 4.65729822],\n",
       "       [ 5.13548267]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fmean, _ = model.predict_f(X_test)\n",
    "P = model.likelihood.invlink(Fmean)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ShapeMismatchError",
     "evalue": "\nTensor shape mismatch.\n  Function: Kernel.__call__\n    Declared: /Users/mattiarosso/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/kernels/base.py:188\n    Argument: X\n      Expected: [batch..., N, D]\n      Actual:   [791, 24]\n    Argument: X2\n      Expected: [batch2..., N2, D]\n      Actual:   [1, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mShapeMismatchError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Xnew \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m0.3\u001b[39m]])\n\u001b[0;32m----> 2\u001b[0m Fmean, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_f(Xnew)\n\u001b[1;32m      3\u001b[0m P \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlikelihood\u001b[39m.\u001b[39minvlink(Fmean\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m P\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/integration/tf.py:76\u001b[0m, in \u001b[0;36minstall_tf_integration.<locals>.TfWrapperPostProcessor.on_wrap.<locals>.wrapped_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_method\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:185\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m _check_specs(pre_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mwith\u001b[39;00m set_shape_checker(checker):\n\u001b[0;32m--> 185\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m arg_map[RESULT_TOKEN] \u001b[39m=\u001b[39m result\n\u001b[1;32m    188\u001b[0m _check_specs(post_specs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/models/vgp.py:213\u001b[0m, in \u001b[0;36mVGP_with_posterior.predict_f\u001b[0;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@inherit_check_shapes\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_f\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m, Xnew: InputData, full_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, full_output_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    205\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MeanAndVariance:\n\u001b[1;32m    206\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m    For backwards compatibility, VGP's predict_f uses the fused (no-cache)\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    computation, which is more efficient during training.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m        model.posterior().predict_f(Xnew, ...)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposterior(posteriors\u001b[39m.\u001b[39;49mPrecomputeCacheType\u001b[39m.\u001b[39;49mNOCACHE)\u001b[39m.\u001b[39;49mfused_predict_f(\n\u001b[1;32m    214\u001b[0m         Xnew, full_cov\u001b[39m=\u001b[39;49mfull_cov, full_output_cov\u001b[39m=\u001b[39;49mfull_output_cov\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/integration/tf.py:76\u001b[0m, in \u001b[0;36minstall_tf_integration.<locals>.TfWrapperPostProcessor.on_wrap.<locals>.wrapped_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_method\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:185\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m _check_specs(pre_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mwith\u001b[39;00m set_shape_checker(checker):\n\u001b[0;32m--> 185\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m arg_map[RESULT_TOKEN] \u001b[39m=\u001b[39m result\n\u001b[1;32m    188\u001b[0m _check_specs(post_specs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/posteriors.py:255\u001b[0m, in \u001b[0;36mAbstractPosterior.fused_predict_f\u001b[0;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39m@check_shapes\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mXnew: [batch..., N, D]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    242\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreturn[0]: [batch..., N, P]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m, Xnew: TensorType, full_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, full_output_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MeanAndVariance:\n\u001b[1;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m    Computes predictive mean and (co)variance at Xnew, including mean_function\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m    Does not make use of caching\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     mean, cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conditional_fused(\n\u001b[1;32m    256\u001b[0m         Xnew, full_cov\u001b[39m=\u001b[39;49mfull_cov, full_output_cov\u001b[39m=\u001b[39;49mfull_output_cov\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_mean_function(Xnew, mean), cov\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/integration/tf.py:76\u001b[0m, in \u001b[0;36minstall_tf_integration.<locals>.TfWrapperPostProcessor.on_wrap.<locals>.wrapped_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_method\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:185\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m _check_specs(pre_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mwith\u001b[39;00m set_shape_checker(checker):\n\u001b[0;32m--> 185\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m arg_map[RESULT_TOKEN] \u001b[39m=\u001b[39m result\n\u001b[1;32m    188\u001b[0m _check_specs(post_specs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/posteriors.py:636\u001b[0m, in \u001b[0;36mVGPPosterior._conditional_fused\u001b[0;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m@inherit_check_shapes\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conditional_fused\u001b[39m(\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m, Xnew: TensorType, full_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, full_output_cov: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    634\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MeanAndVariance:\n\u001b[1;32m    635\u001b[0m     temp_cache \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(c\u001b[39m.\u001b[39mvalue \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_precompute())\n\u001b[0;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conditional_with_precompute(temp_cache, Xnew, full_cov, full_output_cov)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/integration/tf.py:76\u001b[0m, in \u001b[0;36minstall_tf_integration.<locals>.TfWrapperPostProcessor.on_wrap.<locals>.wrapped_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_method\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:185\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m _check_specs(pre_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mwith\u001b[39;00m set_shape_checker(checker):\n\u001b[0;32m--> 185\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m arg_map[RESULT_TOKEN] \u001b[39m=\u001b[39m result\n\u001b[1;32m    188\u001b[0m _check_specs(post_specs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/posteriors.py:601\u001b[0m, in \u001b[0;36mVGPPosterior._conditional_with_precompute\u001b[0;34m(self, cache, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    598\u001b[0m assert_params_false(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conditional_with_precompute, full_output_cov\u001b[39m=\u001b[39mfull_output_cov)\n\u001b[1;32m    600\u001b[0m (Lm,) \u001b[39m=\u001b[39m cache\n\u001b[0;32m--> 601\u001b[0m Kmn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_data, Xnew)  \u001b[39m# [M, ..., N]\u001b[39;00m\n\u001b[1;32m    602\u001b[0m Knn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(\n\u001b[1;32m    603\u001b[0m     Xnew, full_cov\u001b[39m=\u001b[39mfull_cov\n\u001b[1;32m    604\u001b[0m )  \u001b[39m# [..., N] (full_cov = False) or [..., N, N] (True)\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[39mreturn\u001b[39;00m base_conditional_with_lm(\n\u001b[1;32m    607\u001b[0m     Kmn\u001b[39m=\u001b[39mKmn,\n\u001b[1;32m    608\u001b[0m     Lm\u001b[39m=\u001b[39mLm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     white\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhite,\n\u001b[1;32m    614\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/integration/tf.py:76\u001b[0m, in \u001b[0;36minstall_tf_integration.<locals>.TfWrapperPostProcessor.on_wrap.<locals>.wrapped_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_method\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:182\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m             processed_specs\u001b[39m.\u001b[39mappend((arg_value, arg_spec\u001b[39m.\u001b[39mtensor, arg_context))\n\u001b[1;32m    180\u001b[0m     checker\u001b[39m.\u001b[39mcheck_shapes(processed_specs)\n\u001b[0;32m--> 182\u001b[0m _check_specs(pre_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mwith\u001b[39;00m set_shape_checker(checker):\n\u001b[1;32m    185\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/decorator.py:180\u001b[0m, in \u001b[0;36mcheck_shapes.<locals>._check_shapes.<locals>.wrapped_function.<locals>._check_specs\u001b[0;34m(specs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             arg_context \u001b[39m=\u001b[39m StackContext(\n\u001b[1;32m    164\u001b[0m                 bound_error_context,\n\u001b[1;32m    165\u001b[0m                 ParallelContext(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 ),\n\u001b[1;32m    176\u001b[0m             )\n\u001b[1;32m    178\u001b[0m         processed_specs\u001b[39m.\u001b[39mappend((arg_value, arg_spec\u001b[39m.\u001b[39mtensor, arg_context))\n\u001b[0;32m--> 180\u001b[0m checker\u001b[39m.\u001b[39;49mcheck_shapes(processed_specs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/checker.py:315\u001b[0m, in \u001b[0;36mShapeChecker.check_shapes\u001b[0;34m(self, checks)\u001b[0m\n\u001b[1;32m    311\u001b[0m dim_checks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_dims(shape_check)\n\u001b[1;32m    312\u001b[0m \u001b[39mfor\u001b[39;00m dim_spec, actual_dims, shape_possibly_truncated \u001b[39min\u001b[39;00m dim_checks:\n\u001b[1;32m    313\u001b[0m     \u001b[39m# Note that self._check_dim may revive checks from\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39m# `_VariableState.waiting_for_varrank` and add them back to `shape_check_queue`:\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_dim(dim_spec, actual_dims, shape_possibly_truncated, shape_check_queue)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/checker.py:588\u001b[0m, in \u001b[0;36mShapeChecker._check_dim\u001b[0;34m(self, expected, actual_dims, shape_possibly_truncated, shape_checks)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m     \u001b[39m# Anonymous dimension - we don't care about the actual value.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assert(observed_dim\u001b[39m.\u001b[39;49mcheck_and_update(actual_dim, expected\u001b[39m.\u001b[39;49mbroadcastable))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/check_shapes/checker.py:605\u001b[0m, in \u001b[0;36mShapeChecker._assert\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m    601\u001b[0m         shape_error_context \u001b[39m=\u001b[39m ParallelContext(\n\u001b[1;32m    602\u001b[0m             (NoteContext(tensor_spec\u001b[39m.\u001b[39mnote), shape_error_context)\n\u001b[1;32m    603\u001b[0m         )\n\u001b[1;32m    604\u001b[0m     contexts\u001b[39m.\u001b[39mappend(StackContext(context, shape_error_context))\n\u001b[0;32m--> 605\u001b[0m \u001b[39mraise\u001b[39;00m ShapeMismatchError(ParallelContext(\u001b[39mtuple\u001b[39m(contexts)))\n",
      "\u001b[0;31mShapeMismatchError\u001b[0m: \nTensor shape mismatch.\n  Function: Kernel.__call__\n    Declared: /Users/mattiarosso/opt/anaconda3/envs/sproj/lib/python3.8/site-packages/gpflow/kernels/base.py:188\n    Argument: X\n      Expected: [batch..., N, D]\n      Actual:   [791, 24]\n    Argument: X2\n      Expected: [batch2..., N2, D]\n      Actual:   [1, 1]\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([[0.3]])\n",
    "Fmean, _ = model.predict_f(Xnew)\n",
    "P = model.likelihood.invlink(Fmean.numpy()[0])\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.43513593])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
